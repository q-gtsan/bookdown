[["index.html", "Self-learning material book Chapter 1 Vorwort 1.1 CoP 1.2 Einleitung zur Selbstlerneinheit 1.3 Typographische Konvention 1.4 Quelle/weiterf√ºhrende Information 1.5 Feedback", " Self-learning material book Prof.¬†Berenike Herrmann, Prof.¬†Oliver B√∂hm-Kasper, Quy-Sing Glindemann-Tsan 2022-10-20 Chapter 1 Vorwort Dieses ‚Äòbookdown‚Äô dient zur Dokumentation eines interdisziplin√§ren Seminars im Rahmen des Projektes BiLinked mit dem Arbeitsschwerpunkt (CoP) Data Literacy. Erg√§nzend werden die Inhalte des Seminars im Sinne der Nachhaltigkeit respektive Wiederverwendung als Selbstlerneinheit f√ºr Data Literacy zur Verf√ºgung gestellt. 1.1 CoP Diese Community of Practice (CoP) zielt auf die Vermittlung und den Erwerb von ‚ÄûData Literacy‚Äú ab. ‚ÄúDer Begriff beschreibt die F√§higkeit, Daten zu sammeln, zu verwalten, auszuwerten, zu interpretieren und anzuwenden; immer verbunden mit einer kritischen Reflexion der Voraussetzungen und Ziele‚Äù (Sch√ºller, Busch &amp; Hindinger, 2019, S. 10; Ridsdale et al., 2015). In der CoP soll die interdisziplin√§re und kollaborative Zusammenarbeit von Studierenden und Lehrenden in projektf√∂rmig konzipierten Lehrveranstaltungen etabliert werden. Das Thema Data Literacy bietet zahlreiche Ankn√ºpfungspunkte f√ºr realit√§tsnahe Fragestellungen und projektorientierte Arbeitsformen. Es ist damit ein guter Einstieg in die Entwicklung innovativer Lehrformate, die sich f√§cher√ºbergreifend einsetzen lassen. 1.2 Einleitung zur Selbstlerneinheit Diese Selbstlerneinheit basiert auf der Grundlage des Seminars der Universit√§t Bieleld: Erwachsenwerden in der Netz-Literatur. Mixed-methods Analysen von Social Media (S) (SoSe 2022). F√ºr die Inhalte und Durchf√ºhrung sind die Professorin Berenike Herrmann (Fakult√§t Literaturwissenschaft) und der Professor Oliver B√∂hm-Kasper (Fakult√§t Erziehungswissenschaft) verantwortlich gewesen. Auch unabh√§ngig von der Teilnahme am Seminar k√∂nnen Lernende selbst√§ndig dieses Tutorial nutzen, um Twitter-Daten selbst√§ndig zu sammeln und auszuwerten. 1.3 Typographische Konvention Im Sinne der Herangehensweise das vorliegende Material als Selbstlerneinheit zu nutzen, existieren neben dem Haupttext unterschiedliche Textbl√∂cke. Die Textbl√∂cke werden im folgenden vorgestellt: In diesem Textblock stehen √úbungen. In diesem Textblock werden auf notwendige Inhalte oder Ausf√ºhrungen verwiesen. In diesem Textblock wird das Gerlernte √ºberpr√ºft. Wenn Unsicherheiten bei den Fragen bestehen, f√ºhren die dazugeh√∂rigen Links zu den Inhalten zum Nachlesen. 1.3.1 Feedback Am Ende eines Kapitels befindet sich ein Eingabefeld f√ºr (anonyme) Fragen, Anmerkungen/Anregungen und R√ºckemldungen. 1.4 Quelle/weiterf√ºhrende Information Ridsdale, C. et al.¬†(2015). Strategies and Best Practices for Data Literacy Education. Knowledge Synthesis Report. Zugriff am 05.05.2021 unter https://dalspace.library.dal.ca/handle/10222/64578 Sch√ºller, K., Busch, P. &amp; Hindinger, C. (2019). Future Skills: Ein Framework f√ºr Data Literacy. Arbeitspapier Nr. 47. Berlin: Hochschulform Digitalisierung. Zugriff am 05.05.2021 unter https://hochschulforumdigitalisierung.de/sites/default/files/dateien/HFD_AP_Nr_47_DALI_Kompetenzrahmen_WEB.pdf. 1.5 Feedback "],["intro-twitter.html", "Chapter 2 Einf√ºhrung in Social Media - Twitter 2.1 Was ist Twitter? 2.2 Umfrage: Welche Social Media nutzt du? 2.3 Ergebnis der Umfrage im Seminar: 2.4 Quelle/weiterf√ºhrende Information 2.5 Feedback", " Chapter 2 Einf√ºhrung in Social Media - Twitter 2.1 Was ist Twitter? ‚ÄúTwitter ist in erster Linie ein Echtzeitdienst zum Teilen von auf 280 Zeichen limitierten Text-Nachrichten (Tweets) in einem personalisierten, √∂ffentlichen Nachrichtenstrom‚Äù (J√ºrgens &amp; Jungherr, 2011, S. 203). Zudem besticht Twitter durch die schnelle und ungefilterte Verbreitung von Informationen (Parmelee &amp; Bichard, 2012, S. 216). Der Dienst stellt ein weitverbreiteten Kommunikationskanal dar und wird oft als Kommunikationsplattform, soziales Netzwerk oder meist √∂ffentlich einsehbares Online-Tagebuch definiert (Pfaffenberger, 2015, S. 26; Wikipedia.de, 2022). Mehr Informationen sind unter der angegebenen Literatur zu finden. 2.2 Umfrage: Welche Social Media nutzt du? Nimm‚Äô gerne an der Umfrage teil, welche Social Media du nutzt 2.3 Ergebnis der Umfrage im Seminar: Unter den Top 3 waren die am h√§ufigsten genutzten Social Media: WhatsApp Instagram YouTube 2.4 Quelle/weiterf√ºhrende Information J√ºrgens, P., &amp; Jungherr, A. (2011). Wahlkampf vom Sofa aus: Twitter im Bundestagswahlkampf 2009. In E. J. Schweitzer &amp; S. Albrecht (Hrsg.), Das Internet im Wahlkampf. Analysen zur Bundestags- wahl 2009 (S. 201‚Äì225). Wiesbaden: VS Verlag f√ºr Sozialwissenschaften. Parmelee, J. H., &amp; Bichard, S. L. (2012). Politics and the Twitter revolution. How tweets influence the relationship between political leaders and the public (Lexington studies in political communica- tion). Lanham, Md: Lexington Books. Pfaffenberger, Fabian. Twitter als Basis wissenschaftlicher Studien: Eine Bewertung g√§ngiger Erhebungs- und Analysemethoden der Twitter-Forschung. 1. Aufl. 2016. Wiesbaden: Springer Fachmedien Wiesbaden GmbH, 2016. Wikipedia: Twitter 2.5 Feedback "],["einf√ºhrung-in-rstudio-cloud.html", "Chapter 3 Einf√ºhrung in RStudio (Cloud) 3.1 Zugang 3.2 Erste Schritte 3.3 Knowledge-Check 3.4 Feedback", " Chapter 3 Einf√ºhrung in RStudio (Cloud) F√ºr die Durchf√ºhrung von Twitter-Analysen wird ein Analyseprogramm ben√∂tigt, das die Daten sammmeln und auswerten kann. Hierzu wurde im Seminar mit RStudio gearbeitet - konkret mit RStudio Cloud. RStudio ist eine integrierte Entwicklungsumgebung und grafische Benutzeroberfl√§che f√ºr die Statistik-Programmiersprache R. 3.1 Zugang Unter folgendem Link kann das Programm RStudio f√ºr das jeweilige Betriebssystem heruntergeladen werden. Es besteht dar√ºber hinaus die M√∂glichkeit einen RStudio Cloud Zugang bzw. Konto anzulegen, um √ºber den Webbrowser eine webbasierte Version von RStudio zu benutzen. Die Verwendung der webbasierten Version hat den Voreil, dass die Programme R und RStudio nicht lokal installiert werden m√ºssen und immer die aktuellen Versionen zur Verf√ºgung stehen. In Seminaren werden zudem Probleme mit unterschiedlichen Betriebssystemen bei der Ausf√ºhrung von RStudio vermieden. Die Anmeldung und Nutzung der RStudio Cloud ist bei der Verwendng eines Cloud Free-Planes (ausreichend f√ºr Lehr-/Lernkontexte) kostenlos. F√ºr die Twitter-Analysen wird dies empfohlen. 3.1.1 Aufgabe Lade das Programm RStudio herunter + Installiere das Programm auf dem PC/Laptop Empfohlen: Leg ein Konto mit deiner Uni-Emailadresse an, um den Zugang zu RStudio Cloud zu erhalten. 3.1.2 Aufgabe Erstelle einen Twitter-Account Melde dich √ºber die Developer Platform von Twitter mit Ihrem Acount an 3.2 Erste Schritte Im Internet existiert eine Vielzahl an guten Erl√§uterungen, die in RStudio einf√ºhren. An dieser Stelle wird auf das erste und zweite Kapitel des bookdowns von Ellis &amp; Mayer (2022) verwiesen. Um einen guten √úberblick zu erhalten sollen folgende Kapitel durchgearbeitet werden: Kapitel 1 - RStudio Workflow Kapitel 2 - Die R Sprache 3.3 Knowledge-Check Kapitel 1 Wof√ºr sind packages n√ºtzlich? An welcher Stelle k√∂nnen unbekannte Funktionen gesucht werden? Welche Zeichen werden h√§ufig in R verwendet? Kapitel 2 Wie werden Variablen defniert? Welche Datentypen existieren in R? Welche Funktion verr√§t uns den Datentyp? Was sind Listen? Was ist der Unterschied zwischen einer Liste und einem DataFrame? 3.3.1 Erg√§nzende Video-Tutorials zum RStudio-Handling Erg√§nzend ist es sinnvoll praktische Instruktionen durch Video-Tutorials zu nutzen, damit die ersten Schritte im Umgang mit RStudio gelingen. Hierbei werden diese Tutorials empfohlen: gnis - Einf√ºhrung in R/Rstudio Statistik am PC - R mit RStudio - eine Einf√ºhrung in die Bedienung von RStudio Paul Borsdorf - RStudio-Tutorial: Skript nutzen 3.4 Feedback "],["einf√ºhrung-in-die-twitter-api.html", "Chapter 4 Einf√ºhrung in die Twitter API 4.1 Twitter API 4.2 Feedback", " Chapter 4 Einf√ºhrung in die Twitter API 4.1 Twitter API Damit der Zugriff von RStudio Cloud/RStudio auf die Twitter API erfolgen kann, wird ein erh√∂hter Zugang seitens des eigenen Twitter Accounts ben√∂tigt. - Der Status lautet elevated access. F√ºr die Beantragung solch eines Zugangs sind folgende Fragen zu beantworten: How will you use the Twitter API or Twitter Data? Are you planning to analyze Twitter Data? Do you plan to display Tweets or aggregate data about Twitter content outside Twitter? Schau dir zun√§chst das Video-Tutorial von AI Spectrum bis zur Minute 4:39 bzw. das Kapitel Creating Twitter Developer Account with Elevated Access an - YouTube. Erstelle nun einen Developer-Account wie im Tutorial: Erstelle eine APP Hinterlege die individuellen Infos zu deinem Account: API, API Key Secret, Bearer-Token Generiere und hinterlege deinen Access Token und Access Token Secret Bewerbe dich f√ºr den elevated access durch die Beantwortung der obigen Fragen Link zum Developer-Portal von Twitter Der konktrete Zugriff auf die Twitter API √ºber RStudio wird im sp√§teren Verlauf erl√§utert. An dieser Stelle wird ausdr√ºcklich darauf hingewiesen, dass der Status: elevated acess erforderlich ist, um mit RStudio Cloud/ RStudio einen Zugriff auf die Twitter API zu erhalten. Zur Erstellung solch eines Zugangs ist die Angabe einer g√ºltigen mobilen Rufnummer notwendig. Zur Erstellung solch eines Zugangs ist die Angabe einer g√ºltigen mobilen Rufnummer in den Twitter Einstellungen notwendig. 4.2 Feedback "],["organisation-des-virtuellen-workplace.html", "Chapter 5 Organisation des virtuellen Workplace 5.1 Vorschlag f√ºr die Arbeitsorganisation 5.2 Feedback", " Chapter 5 Organisation des virtuellen Workplace Der erste Schritt ist die Vorbereitung des Arbeitsplatzes. Das betrifft Das Aufrufen von RStudio/RStudio Cloud Die Herstellung einer Arbeitsorganisation (Ordnerstruktur) Diese Schrittfolgen sind f√ºr alle Aufgaben gleich und werden vor der Bearbeitung einer AUfgabe voran gestellt. 5.1 Vorschlag f√ºr die Arbeitsorganisation 5.1.1 RStudio Bearbeitung einer neuen Aufgabe √ñffne RStudio Erstelle ein Ordner mit einem sinnvollen Namen, damit du in der Zukunft auch noch wei√üt, wo deine Skripte zu finden sind Erstelle ein Projekt √ºber den obigen Reiter ‚ÄúFile -&gt; New Project‚Äù. Gib dem Projekt einen sinnvollen Namen. Anschlie√üend erstelle in RStudio ein neues Skript. Speicher das Skript ebenfalls unter einem sinnvollen Namen in dem eben erstellten Ordner ab. √úber das Skript werden die Aufgaben bearbeitet. Es ist meistens sinnvoll ein weiteres Skript zu erstellen, um bspw. eine neue oder eine Teilaufgabe zu bearbeiten. Das sorgt f√ºr mehr √úbersicht. Bearbeitung einer bestehenden Aufgabe Gehe in den Ordner, in dem das Projekt abgespeichert ist. √ñffne die Projektdatei mit der Endung (.rProj). √úber diese Vorgehensweise, √∂ffnet sich RStudio mit all den Skripten, die zuletzt im Projekt ge√∂ffnet wurden. 5.1.2 RStudio Cloud Bearbeitung einer neuen Aufgabe Log dich in RStudio Cloud ein Gehe in dein Workspace und erstelle ein neues Projekt mit einem sinnvollen Namen. Damit wei√üt du in der Zukunft auch noch, wo deine Skripte zu finden sind Anschlie√üend erstelle in RStudio ein neues Skript. Speicher das Skript ebenfalls unter einem sinnvollen Namen in dem eben erstellten Ordner ab. √úber das Skript werden die Aufgaben bearbeitet. Es ist meistens sinnvoll ein weiteres Skript zu erstellen, um bspw. eine neue oder eine Teilaufgabe zu bearbeiten. Das sorgt f√ºr mehr √úbersicht. Bearbeitung einer bestehenden Aufgabe Log dich in RStudio Cloud ein und gehe in dein Workspace, in dem das Projekt abgespeichert ist. √ñffne das Projekt √úber diese Vorgehensweise, √∂ffnet sich RStudio mit all den Skripten, die zuletzt im Projekt ge√∂ffnet wurden. 5.2 Feedback "],["erste-lerneinheit---twitter-authentifizierung-erste-analysen.html", "Chapter 6 Erste Lerneinheit - Twitter Authentifizierung &amp; erste Analysen‚Äù 6.1 Workspace erstellen 6.2 Authentifizierung 6.3 Finger√ºbung 6.4 Quelle 6.5 Feedback", " Chapter 6 Erste Lerneinheit - Twitter Authentifizierung &amp; erste Analysen‚Äù F√ºr die anschlie√üende Bearbeitung sind der Zugang zu RStudio Cloud/RStudio sowie der Status elevated Access im Twitter-Developer Account erforderlich. Gehe in die entsprechenden Kapitel zur√ºck, wenn die Voraussetzungen noch nichte erf√ºllt sind. 6.1 Workspace erstellen Bereite dein Workplace vor (siehe Kapitel 4). √ñffne ein leeres Skript. 6.2 Authentifizierung 6.2.1 Einlesen von notwendigen Paketen Zun√§chst werden im Skript die erforderlichen Pakete installiert und aufgerufen. Die Pakete beinhalten bestimmte Funktionen, die nicht im Basis-Umfang enthalten sind. Diese Funktionen sind f√ºr die Twitter-API und die ersten Analysen wichtig. Code # load twitter library library(rtweet) # plotting and pipes - tidyverse! library(tidyverse) # text mining library library(tidytext) Code # install packages install.packages(c(&quot;rtweet&quot;,&quot;tidytext&quot;,&quot;tidyverse&quot;)) # load twitter library library(rtweet) # plotting and pipes - tidyverse! library(tidyverse) # text mining library library(tidytext) 6.2.2 Erstellen eines Authentifikations-Token Im n√§chsten Schritt wird eine Verbindung zur Twitter API √ºber das Paket rtweet hergestellt. Daf√ºr m√ºssen die Informationen (Bearer-Token), die im 4.1 hinterlegt wurden, eingegeben werden. Code # rtweet_app() Funktion um die eigene Twitter APP zu authentifizieren. # Das ist die naheliegendste Funktionin Bezug auf das Sammeln von Daten auth &lt;- rtweet_app( bearer_token = &quot;dein_bearer_token&quot; ) # authenticate your rtweet app through the function &#39;auth_as()&#39; with the saved ojbect &#39;auth&#39; auth_as(auth) Sofern alles geklappt hat, erscheint keine Fehlermeldung. Im n√§chsten Code-Abschnitt testen wir die Verbindung zur Twitter-API mit einer Twitter-Suche nach dem Hashtag #Bielefeld. Die Ergebnisse werden in dem Objekt bielefeld_tweets gespeichert. 6.2.3 Einlesen von Twitter-Daten Code # Erster Abruf von Twitter-Daten bielefeld_tweets &lt;- search_tweets(q = &quot;#Bielefeld&quot;, n = 500) 6.2.4 Ergebnisse Nachdem die Tweets heruntergeladen wurden, k√∂nnen wir nun einen Blick auf die Ergebnisse werfen: Code #√úbersicht √ºber Datensatz #√úbersicht √ºber die Struktur des Datensatzes head (bielefeld_tweets) ## # A tibble: 6 √ó 43 ## created_at id id_str full_‚Ä¶¬π trunc‚Ä¶¬≤ displ‚Ä¶¬≥ entities ## &lt;dttm&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;list&gt; ## 1 2022-10-19 14:10:58 1.58e18 158270586634‚Ä¶ &quot;Seit ‚Ä¶ FALSE 279 &lt;named list&gt; ## 2 2022-10-20 15:18:00 1.58e18 158308512372‚Ä¶ &quot;#Guet‚Ä¶ FALSE 277 &lt;named list&gt; ## 3 2022-10-20 15:17:53 1.58e18 158308509556‚Ä¶ &quot;#RB61‚Ä¶ FALSE 179 &lt;named list&gt; ## 4 2022-10-20 15:09:22 1.58e18 158308295105‚Ä¶ &quot;Hallo‚Ä¶ FALSE 240 &lt;named list&gt; ## 5 2022-10-20 15:02:16 1.58e18 158308116368‚Ä¶ &quot;#RE82‚Ä¶ FALSE 155 &lt;named list&gt; ## 6 2022-10-20 15:00:01 1.58e18 158308059886‚Ä¶ &quot;#RB61‚Ä¶ FALSE 129 &lt;named list&gt; ## # ‚Ä¶ with 36 more variables: metadata &lt;list&gt;, source &lt;chr&gt;, ## # in_reply_to_status_id &lt;dbl&gt;, in_reply_to_status_id_str &lt;chr&gt;, ## # in_reply_to_user_id &lt;dbl&gt;, in_reply_to_user_id_str &lt;chr&gt;, ## # in_reply_to_screen_name &lt;chr&gt;, geo &lt;list&gt;, coordinates &lt;list&gt;, ## # place &lt;list&gt;, contributors &lt;lgl&gt;, is_quote_status &lt;lgl&gt;, ## # retweet_count &lt;int&gt;, favorite_count &lt;int&gt;, favorited &lt;lgl&gt;, ## # retweeted &lt;lgl&gt;, possibly_sensitive &lt;lgl&gt;, lang &lt;chr&gt;, ‚Ä¶ Code #√úbersicht √ºber die Variablennamen (Spaltennamen) names (bielefeld_tweets) ## [1] &quot;created_at&quot; &quot;id&quot; ## [3] &quot;id_str&quot; &quot;full_text&quot; ## [5] &quot;truncated&quot; &quot;display_text_range&quot; ## [7] &quot;entities&quot; &quot;metadata&quot; ## [9] &quot;source&quot; &quot;in_reply_to_status_id&quot; ## [11] &quot;in_reply_to_status_id_str&quot; &quot;in_reply_to_user_id&quot; ## [13] &quot;in_reply_to_user_id_str&quot; &quot;in_reply_to_screen_name&quot; ## [15] &quot;geo&quot; &quot;coordinates&quot; ## [17] &quot;place&quot; &quot;contributors&quot; ## [19] &quot;is_quote_status&quot; &quot;retweet_count&quot; ## [21] &quot;favorite_count&quot; &quot;favorited&quot; ## [23] &quot;retweeted&quot; &quot;possibly_sensitive&quot; ## [25] &quot;lang&quot; &quot;retweeted_status&quot; ## [27] &quot;quoted_status_id&quot; &quot;quoted_status_id_str&quot; ## [29] &quot;quoted_status&quot; &quot;text&quot; ## [31] &quot;favorited_by&quot; &quot;scopes&quot; ## [33] &quot;display_text_width&quot; &quot;quoted_status_permalink&quot; ## [35] &quot;quote_count&quot; &quot;timestamp_ms&quot; ## [37] &quot;reply_count&quot; &quot;filter_level&quot; ## [39] &quot;query&quot; &quot;withheld_scope&quot; ## [41] &quot;withheld_copyright&quot; &quot;withheld_in_countries&quot; ## [43] &quot;possibly_sensitive_appealable&quot; Code #Inhalte der ersten 10 Tweets anzeigen bielefeld_tweets$text[1:10] ## [1] &quot;Seit fast 2 Jahren recherchieren wir zu einem unfassbaren Verbrechen in der #Bielefeld‚Äãer #Bethel-Klinik: Ein Assistenzarzt bet√§ubte und vergewaltigte rund 30 Patientinnen. Unsere Reportage dazu heute 22:15 im rbb Fernsehen, jetzt schon in der Mediathek:\\n\\nhttps://t.co/gH1QibgmiX https://t.co/PQRhhR6bKx&quot; ## [2] &quot;#Guetersloh #Bielefeld #Osnabrueck @RadioGuetersloh @RadioBielefeld @nwnews @westfalenblatt #HalleWestfalen #Wub \\nIch freue mich drauf, mit euch zusammen zu essen und zu lachen! Lesung am 29.10. im Caf√© Altes Pfarrhaus in Halle Westf. Reservierung hier: https://t.co/JCyT2zh5xf https://t.co/a1slLaBtgr&quot; ## [3] &quot;#RB61 #Hengelo - #Bielefeld Hbf | Versp√§tungen | von Wissingen bis Bielefeld Hbf | Technische St√∂rung an der Strecke | St√∂rung von 15:15 bis vsl. 16:00 Uhr https://t.co/Z8Er2H7m3I&quot; ## [4] &quot;Hallo Ostwestfalen! \\nAm Sonntag, den 30.11., bin ich ins Bauernhausmuseum nach #Bielefeld eingeladen. Ich freue mich sehr auf Vortrag &amp;amp; Diskussion √ºber #Biodiversit√§t in meiner alten Heimat OWL.\\nKommt zahlreich!\\n\\nhttps://t.co/nEFpHUdHC0&quot; ## [5] &quot;#RE82 #Bielefeld Hbf - #Altenbeken | Versp√§tungen | von Altenbeken bis Altenbeken | Zugfolge | St√∂rung von 15:01 bis vsl. 15:09 Uhr https://t.co/Z8Er2H7m3I&quot; ## [6] &quot;#RB61 #Hengelo 15:34 nach #Bielefeld Hbf 17:48 #Teilausfall von #Hengelo bis Oldenzaal aufgrund eines nicht NL-f√§higen Fahrzeugs.&quot; ## [7] &quot;RT @eurobahn_info: #RE78 #Nienburg (Weser) - #Bielefeld Hbf (beide Ri.) | Zugausf√§lle | von Nienburg (Weser) bis Bielefeld Hbf (beide Ri.)‚Ä¶&quot; ## [8] &quot;#RE78 #Nienburg (Weser) - #Bielefeld Hbf (beide Ri.) | Zugausf√§lle | von Nienburg (Weser) bis Bielefeld Hbf (beide Ri.) | Kurzfristiger Personalausfall | St√∂rung von 19:24 bis vsl. 01:05 Uhr https://t.co/Z8Er2Hop5I&quot; ## [9] &quot;Revengeüòà #VfB #vfbstuttgart #bielefeld https://t.co/jt3OQKaK9M&quot; ## [10] &quot;RT @ZuginfoNRW: #RE78 #Zugausfall #Bielefeld Hbf 15:24 - #Nienburg (Weser) 16:49. Aufgrund eines kurzfristigen Personalausfalls.&quot; So sieht der Output aus, wenn die Authentifikation und die Suche geklappt haben. 6.2.5 Abspeichern Zur Erleichterung speichern wir unsere Authentifizierung ab, um die erneute Authentifizierung beim n√§chsten Mal nicht wiederholen zu m√ºssen. Hierbei nutzen wir die Funktion auth_save aus dem rtweet-Paket, um die Zugangsdaten unter den Namen ‚ÄúMeine App‚Äù abzuspeichern. Code # Abspeichern der Zugangsdaten auth_save(auth, &quot;Meine App&quot;) ## Saving auth to &#39;/Users/q.t./Library/Preferences/org.R-project.R/R/rtweet/Meine ## App.rds&#39; Wenn wir in der n√§chsten Session die Twitter API benutzen m√∂chten, rufen wir folgenden Befehl mit dem selbstbestimmten Namen ‚ÄúMeine App‚Äù f√ºr die Authentifizierung auf. Code auth_as(&quot;Meine App&quot;) 6.3 Finger√ºbung Arbeite folgende √úbungen mithilfe der rtweet Dokumentation durch: Link. Hierbei ist das Ziel sich mit den Werkzeugen vertraut zu mahen. Suche nach dem Hashtag ‚Äúmicropeotry‚Äù und speicher die Ergebnisse ab. Schau dir die tweets an. Suche nach den user IDs der Twitter-Accounts, die die Universit√§t Bielefeld ‚Äú@unibielefeld‚Äù folgt Suche nach Followern von der Uni Bielefeld ‚Äú@unibielefeld‚Äù Suche nach der Timeline von Bielefeld 6.4 Quelle Blogbeitrag zur Nutzung des rtweet-Pakets 6.5 Feedback "],["beispiel-analyse.html", "Chapter 7 Beispiel-Analyse 7.1 Workplace &amp; Authentifizierung Twitter 7.2 Tweets-Suche 7.3 H√§ufigste User der Hashtags #Bielefeld oder #bielefeld 7.4 Quelle 7.5 Feedback", " Chapter 7 Beispiel-Analyse In diesem Kapitel werden die Tweets mit dem Hashtag #Bielefeld respektive #bielefeld untersucht und visualisiert. Setzt dich mit dem Kapitel auseinander Such dir einen Hashtag aus und f√ºhre die Methoden und Funktionen f√ºr diesen Hashtag wie in diesem Kapitel aus Der Sinn dieser √úbung ist es, die Programmiersprache R respektive RStudio kennenzulernen. 7.1 Workplace &amp; Authentifizierung Twitter An dieser Stelle wird nur auf die Herstellung des virtuellen Workplaces hingewiesen. Des Weiteren benutzen wir nun mithilfe der Funktion ‚Äôauth_as(‚ÄúMeine APP‚Äù)‚Äôdie vereinfachte Authentifikations-Methode; ohne Zugangsinformationen eingeben zu m√ºssen. Zun√§chst wird das notwendige Paket rtweet eingelesen. Code # Einlesen des notwendigen Packages library(rtweet) auth_as(&quot;Meine App&quot;) 7.2 Tweets-Suche Wir speichern die Tweets in dem Objekt ‚ÄúBielefeld_tweets‚Äù ab. Die Analyse und die Visualierung basiert auf dem Objekt, der die notwendigen Daten enth√§lt. Code # Abruf von Tweets unter den Hashtags #Bielefeld oder #bielefeld Bielefeld_tweets &lt;- search_tweets(&quot;#Bielefeld OR #bielefeld&quot;, n=9000, #Suche nach Tweets #Bielefeld oder #bielefeld, max. 9000 Tweets lang = &quot;de&quot;, #Sprache der Tweets: Deutsch include_rts = TRUE) #Retweets sollen inkludiert sein 7.3 H√§ufigste User der Hashtags #Bielefeld oder #bielefeld Um die zehn h√§ufigsten User aus dem Datensatz zu erhalten, wird zur Vereinfachung des Programmierens das Paket tidyverse benutzt. Das Paket bietet die M√∂glichkeit direkt √ºber den Code einen leserfreundlicheren (&amp; besser nachvollziehbaren) Code zu erstellen, ohne viel kommentieren zu m√ºssen. F√ºr die Auflistung der h√§ufigsten User sind die Account-Namen notwendig, die √ºber die Funktion users_data(Bielefeld_tweets) eingeholt werden. Dies wird in dem Objekt tweets_bi abgespeichert. Code #Notwendiges Paket f√ºr die pipe &quot; %&gt;% &quot;-Programmierung library (tidyverse) tweets_bi &lt;- users_data(Bielefeld_tweets) #u.a. die Daten zum Accout-Namen einholen tweets_bi %&gt;% #Zugriff auf Daten mit #Bielefeld-Tweets count (name) %&gt;% #Anzahl der Twitter-Nutzer-Namen top_n(10) %&gt;% #Top 10 werden ausgew√§hlt arrange(desc(n)) #in absteigender Reihenfolge ausgeben ## # A tibble: 17 √ó 2 ## name n ## &lt;chr&gt; &lt;int&gt; ## 1 eurobahn 296 ## 2 (Kurzfristiger) Personalausfall 129 ## 3 zuginfo.nrw 99 ## 4 Tempo-Team Personaldienstleistungen GmbH 23 ## 5 Polizei NRW BI 15 ## 6 Neue Westf√§lische 12 ## 7 Fuchsbaubewohner ü¶ä 7 ## 8 iranprotestsgermany 6 ## 9 Michael Gugat 5 ## 10 ‚ñà‚ñà‚ñà.dissent.is/‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 4 ## 11 hallo24.de 4 ## 12 Kontraste 4 ## 13 LOUISEXYZJEANS VON DE R√ñYAL 4 ## 14 presseportal.de 4 ## 15 Rosella Wenninger 4 ## 16 Simon N. ~ üíôüá©üá™ 4 ## 17 Westfalen-Blatt 4 7.3.1 Visualisierung der Daten: 7.3.1.1 √úber eine Tabelle mit dem Paket gt Um eine ansprechendere Visualisierung zu generieren, nutzen wir das Paket gt. Daf√ºr ist das Paket zu installieren: Code install.packages(&quot;gt&quot;) Anschlie√üend wird das Paket eingelesen und die Tabelle wird erstellt. Die Dokumentation zu dem Paket sind optional hier nachzulesen. Code #Notwendiges Paket f√ºr gt-Tables library (gt) tweets_bi %&gt;% count (name) %&gt;% top_n(10) %&gt;% arrange(desc(n)) %&gt;% gt() %&gt;% #Erzeugung der Tabelle tab_header ( #&quot;Kopf&quot; der Tabelle layouten title = &quot;H√§ufigste User des Hashtags #Bielefeld oder #bielefeld&quot;, #Tabellen-Titel subtitle = &quot;Absolute Anzahl&quot;) %&gt;% # Untertitel cols_label(name = &quot;Twitter-Nutzer-Name&quot;, n = &quot;Anzahl der Tweets&quot;) %&gt;% #Beschriftung der Spalten tab_source_note( source_note = paste(&quot;Source: Data collected from TwitterAPI via rtweet-package &quot;,Sys.Date()) ) #Angabe der Quellen html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #bmzqheolfd .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #bmzqheolfd .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #bmzqheolfd .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #bmzqheolfd .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #bmzqheolfd .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bmzqheolfd .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #bmzqheolfd .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #bmzqheolfd .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #bmzqheolfd .gt_column_spanner_outer:first-child { padding-left: 0; } #bmzqheolfd .gt_column_spanner_outer:last-child { padding-right: 0; } #bmzqheolfd .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #bmzqheolfd .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #bmzqheolfd .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #bmzqheolfd .gt_from_md > :first-child { margin-top: 0; } #bmzqheolfd .gt_from_md > :last-child { margin-bottom: 0; } #bmzqheolfd .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #bmzqheolfd .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #bmzqheolfd .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #bmzqheolfd .gt_row_group_first td { border-top-width: 2px; } #bmzqheolfd .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #bmzqheolfd .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #bmzqheolfd .gt_first_summary_row.thick { border-top-width: 2px; } #bmzqheolfd .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bmzqheolfd .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #bmzqheolfd .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #bmzqheolfd .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #bmzqheolfd .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bmzqheolfd .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #bmzqheolfd .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #bmzqheolfd .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #bmzqheolfd .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #bmzqheolfd .gt_left { text-align: left; } #bmzqheolfd .gt_center { text-align: center; } #bmzqheolfd .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #bmzqheolfd .gt_font_normal { font-weight: normal; } #bmzqheolfd .gt_font_bold { font-weight: bold; } #bmzqheolfd .gt_font_italic { font-style: italic; } #bmzqheolfd .gt_super { font-size: 65%; } #bmzqheolfd .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #bmzqheolfd .gt_asterisk { font-size: 100%; vertical-align: 0; } #bmzqheolfd .gt_indent_1 { text-indent: 5px; } #bmzqheolfd .gt_indent_2 { text-indent: 10px; } #bmzqheolfd .gt_indent_3 { text-indent: 15px; } #bmzqheolfd .gt_indent_4 { text-indent: 20px; } #bmzqheolfd .gt_indent_5 { text-indent: 25px; } H√§ufigste User des Hashtags #Bielefeld oder #bielefeld Absolute Anzahl Twitter-Nutzer-Name Anzahl der Tweets eurobahn 296 (Kurzfristiger) Personalausfall 129 zuginfo.nrw 99 Tempo-Team Personaldienstleistungen GmbH 23 Polizei NRW BI 15 Neue Westf√§lische 12 Fuchsbaubewohner ü¶ä 7 iranprotestsgermany 6 Michael Gugat 5 ‚ñà‚ñà‚ñà.dissent.is/‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 4 hallo24.de 4 Kontraste 4 LOUISEXYZJEANS VON DE R√ñYAL 4 presseportal.de 4 Rosella Wenninger 4 Simon N. ~ üíôüá©üá™ 4 Westfalen-Blatt 4 Source: Data collected from TwitterAPI via rtweet-package 2022-10-20 7.3.1.2 √úber ein Diagram mit dem Paket ggplot2 F√ºr diese Visualisierung wird das Paket ggplot2 ben√∂tigt, welches zuvorderst eingelesen wird (und wenn notwendig installiert wird). Code install.packages(&quot;ggplot2&quot;) Die Erstellung und Ausgabe des Diagramms erfolgt in diesem Abschnitt. Code #notwendiges Paket library(ggplot2) #Als Graphik tweets_bi %&gt;% count(name, sort = TRUE) %&gt;% na.omit() %&gt;% top_n(10) %&gt;% ggplot(aes(reorder (x =name, n), y = n)) + #Erzeugung eines Diagramms geom_col(fill = &#39;steelblue4&#39;) + #Farbe der Balken coord_flip() + #Diagramm um 90 Grad gedreht labs(x = &quot;Name&quot;, #Beschriftung der X-Achse y = &quot;Anzahl&quot;, #Beschriftung der y-Achse title = &quot;Who is tweeting? &quot;, #Diagrammtitel subtitle = &quot;under Hashtag #Bielefeld or #Bielefeld&quot;, #Untertitel des Diagramms caption = paste(&quot;Source: Data collected from TwitterAPI via rtweet-package &quot;,Sys.Date())) #Quellenangabe f√ºr Diagramm In der obigen Darstellung werden die Daten in einem Balkendiagramm pr√§sentiert. Es ist auch m√∂glich sich die Anzahl der Tweets pro Tag anzeigen zu lassen. Hier wird das Paket lubridate ben√∂tigt, welches installiert und eingelesen wird. Code #notwendiges Paket install.packages(&quot;lubridate&quot;) Im Anschluss werden die notwendigen Daten definiert und in einer Zeitreihe durch Balken dargestellt. Code library (lubridate) Bielefeld_tweets$date = date(Bielefeld_tweets$created_at) #Abspeicherung einer neuen Variable Datum Bielefeld_tweets_date = data.frame(table(Bielefeld_tweets$date)) #Erzeugung eines neuen Datensatz mit Datum und Anzahl der Tweets colnames(Bielefeld_tweets_date) = c(&#39;Datum&#39;,&#39;Total.Tweets&#39;) #Umbenennung der Variablennamen # Create data viz ggplot(Bielefeld_tweets_date)+ #unterste Ebene des Diagramm erzeugen geom_bar(aes(x = Datum, #Spezifizierung X-Achse y = Total.Tweets, #Spezifizierung y-Achse fill = I(&#39;cornflowerblue&#39;)), #Farbe der Balken stat = &#39;identity&#39;, #Verwendung der absoluten Werte aus dem Data.Frame show.legend = FALSE)+ #keine Legende anzeigen geom_hline(yintercept = mean(Bielefeld_tweets_date$Total.Tweets), #horizontale Linie basierend auf dem Mittelwert der Anzahl an Tweets col = (&#39;red&#39;), #Farbe rot size = 0.5)+ #Dicke der Linie geom_text(aes(fontface = &#39;italic&#39;, #kursiver Text label = paste(&#39;Mittelwert:&#39;, ceiling(mean(Bielefeld_tweets_date$Total.Tweets)), #Einf√ºgen des automatisch berechneten Mittelwertes &#39;Tweets pro Tag&#39;), x = 1, #Position des Texts auf der X-Achse (erstes Datum) y = mean(Bielefeld_tweets_date$Total.Tweets)+20), #Position auf der Y-Achse, +20 √ºber dem ersten Balken hjust = &#39;left&#39;, #Textposition links size = 4, #Textgr√∂√üe col = (&#39;red&#39;) )+ #Textfarbe labs(title = &#39;Anzahl der Tweets pro Tag &#39;, #Diagrammtitel subtitle = &#39;mit dem Hashtag #Bielefeld oder #bielefeld&#39;, #Untertitel des Diagramms caption = paste(&quot;Source: Data collected from TwitterAPI via rtweet-package &quot;,Sys.Date()))+ xlab(&#39;Datum&#39;)+ #Beschriftung x-Achse ylab(&#39;Anzahl der Tweets&#39;)+ #Beschriftung y-Achse theme_bw() #Diagramm-Theme schwarz-wei√ü 7.4 Quelle Zur Homepage des Pakets: ggplot2 Zur Homepage des Pakets: gt Zur Homepage des Pakets: lubridate Zur Homepage des Pakets: tidyverse 7.5 Feedback "],["freq_table_analysis.html", "Chapter 8 Zweite Lerneinheit - Twitter Analyse: H√§ufigkeitstabelle &amp; Wordcloud 8.1 Vorbereitung 8.2 Twitter Suche 8.3 Data Pre-Processing: Cleaning 8.4 Data Pre-Processing: Transformieren 8.5 Data Visualization: H√§ufigkeitstabelle 8.6 Eigene Stopw√∂rter erstellen 8.7 Data Visualization: Word-Cloud 8.8 Quelle 8.9 Feedback", " Chapter 8 Zweite Lerneinheit - Twitter Analyse: H√§ufigkeitstabelle &amp; Wordcloud Dieser Abschnitt behandelt die Visualisierung einer H√§ufigkeitstabelle und einer Wordcloud auf der Grundlage von twitter-Daten. 8.1 Vorbereitung Daf√ºr ist es hilfreich sich vorbereitend die Website ‚ÄûWork With Twitter Social Media Data in R - An Introduction - Lesson 3: ‚ÄúText Mining Twitter Data With TidyText in R‚Äù anzuschauen. In diesem Eintrag wird die Bedeutung der Begriffe wie ‚ÄòData Munging‚Äô respektive ‚ÄòData Pre-Processing‚Äô f√ºr die Visualierung hervorgehoben und deren Handhabarkeit in R knapp erl√§utert. 8.2 Twitter Suche F√ºr diese Analyse werden wir nach den Hashtags #Erziehung und #Lyrik suchen. Vorab ist die Authentifizierung mit der Twitter-API notwendig. Code #Abruf von Tweets unter den Hashtags #Erziehung &amp; #Lyrik erziehung_tweets &lt;- search_tweets(&quot;#Erziehung&quot;, n=10000, lang = &quot;de&quot;, include_rts = TRUE) lyrik_tweets &lt;- search_tweets(&quot;#Lyrik&quot;, n=10000, lang = &quot;de&quot;, include_rts = TRUE) 8.3 Data Pre-Processing: Cleaning Ein wesentlicher Bestandteil der Datensammlung respektive der Datenbeschaffung ist die Bereinigung der Daten. Hierbei werden beispielsweise auf Fehler und Inkonsistenz der Daten gepr√ºft. Des Weiteren werden irrelevante und korrupte Daten identifiziert und korrigiert. Mit diesem Schritt wird daf√ºr gesorgt, dass die Daten, die wir pr√§sentieren und weiterverarbeiten wollen konsistent und valide sind. Vorerst schauen wir uns die Twitter Beitr√§ge an. Code # Anzeige der ersten Eintr√§ge in der Variable &quot;text&quot; head (erziehung_tweets$text) ## [1] &quot;RT @princessfeetvie: Guten Morgen, Ich vermisse den Sommerü•∫‚ù§Ô∏è \\n\\nMeldet euch bei mir per DM wenn ihr Unterw√ºrfig seit..\\n@princessfeetvie \\n\\n#‚Ä¶&quot; ## [2] &quot;RT @princessfeetvie: Hallo wer will einer jungen Herrin dienen?\\nSchreibt mich an. DM ‚ù§Ô∏è\\n#domina #feet #soles #findom #femdom #cuckold #cuck‚Ä¶&quot; ## [3] &quot;RT @MissSarina4: Kriech n√§he#Nylonlove #Genuss #Nylon #Anbeten #Dienen #Mistress #Fetisch #Fu√ü #Kiarashoes #Erniedrigung #Pantolette #Onlin‚Ä¶&quot; ## [4] &quot;RT @irisdarkphanta1: #erziehung ist sehr vielf√§ltig‚Ä¶. Hier eine unserer Variationen ‚Ä¶.. @Tom_PHoToToM https://t.co/JdUUgY4iAG&quot; ## [5] &quot;Kriech n√§he#Nylonlove #Genuss #Nylon #Anbeten #Dienen #Mistress #Fetisch #Fu√ü #Kiarashoes #Erniedrigung #Pantolette #Onlineerziehung #Fu√üfetisch #nylonfetish #Fu√üverehrung #highheels #Fu√ü #Feinstrumpfhose #Anbetung #Fetisch #Fu√ü #Fetischmahlzeit #Heels #session #Erziehung https://t.co/oKRQtiEYk5&quot; ## [6] &quot;Bertelsmann-Studie zu Kitas l√∂st kontroverse Reaktionen aus #Bildung #Sachsen #Erziehung #Familie #Dresden https://t.co/Vod5AygzyC&quot; Code head (lyrik_tweets$text) ## [1] &quot;RT @o_franco_aleman: O komm,\\nKomm zu mir,\\nIch bin ja so s√º√ü nach dir.\\nIch deine Lebendige,\\nDeine weilende Zier,\\nVergehe nach dir.\\n\\nPeter Hi‚Ä¶&quot; ## [2] &quot;#FreieTexte #FreieTexte #Lyrik #Ichwolltesw√§reallesnursch√∂n #Gedicht Ich wollt, es w√§re alles nur sch√∂n!: Ich wollt`, es w√§re alles nur sch√∂n ‚Äì jeder w√ºrde den anderen allein als Gl√ºcksfall seh`n! Ein Miteinander w√§re weit und breit und nirgendwo‚Ä¶ https://t.co/bjrrWP5Xgn&quot; ## [3] &quot;RT @o_franco_aleman: O komm,\\nKomm zu mir,\\nIch bin ja so s√º√ü nach dir.\\nIch deine Lebendige,\\nDeine weilende Zier,\\nVergehe nach dir.\\n\\nPeter Hi‚Ä¶&quot; ## [4] &quot;RT @o_franco_aleman: O komm,\\nKomm zu mir,\\nIch bin ja so s√º√ü nach dir.\\nIch deine Lebendige,\\nDeine weilende Zier,\\nVergehe nach dir.\\n\\nPeter Hi‚Ä¶&quot; ## [5] &quot;RT @o_franco_aleman: Im Namen der #Liebe \\nverschenken wir das #Herz. \\nIch verblute.\\n\\nPeter Turrini\\n\\n#lyrik #poesie #fotografie https://t.co‚Ä¶&quot; ## [6] &quot;RT @o_franco_aleman: O komm,\\nKomm zu mir,\\nIch bin ja so s√º√ü nach dir.\\nIch deine Lebendige,\\nDeine weilende Zier,\\nVergehe nach dir.\\n\\nPeter Hi‚Ä¶&quot; Als erstes wird der HTML-Text entfernt. Dabei werden die bereinigten Texte in einer neuen Spalte ‚Äústripped_text‚Äù abgespeichert. Code # Bereinigung um URLs und teilweise html-function # Bereinigung um URLS erziehung_tweets$stripped_text &lt;- gsub(&quot;http.*&quot;,&quot;&quot;, erziehung_tweets$text) erziehung_tweets$stripped_text &lt;- gsub(&quot;https.*&quot;,&quot;&quot;, erziehung_tweets$stripped_text) # Bereinigung um URLS lyrik_tweets$stripped_text &lt;- gsub(&quot;http.*&quot;,&quot;&quot;, lyrik_tweets$text) lyrik_tweets$stripped_text &lt;- gsub(&quot;https.*&quot;,&quot;&quot;, lyrik_tweets$stripped_text) 8.3.1 Aufgabe Um die Schritte der Datenbereinigung praktisch nachzuvollziehen, bereinige die Texteintr√§ge erneut durch und entferne die HTML-Syntax-Zeichen: &amp;amp; mit &amp; und die \\n mit \" \"(Leerzeichen) . Nach der ersten groben Bereinigung betrachten wir nun das Ergebnis. Code head (erziehung_tweets$stripped_text) ## [1] &quot;RT @princessfeetvie: Guten Morgen, Ich vermisse den Sommerü•∫‚ù§Ô∏è Meldet euch bei mir per DM wenn ihr Unterw√ºrfig seit.. @princessfeetvie #‚Ä¶&quot; ## [2] &quot;RT @princessfeetvie: Hallo wer will einer jungen Herrin dienen? Schreibt mich an. DM ‚ù§Ô∏è #domina #feet #soles #findom #femdom #cuckold #cuck‚Ä¶&quot; ## [3] &quot;RT @MissSarina4: Kriech n√§he#Nylonlove #Genuss #Nylon #Anbeten #Dienen #Mistress #Fetisch #Fu√ü #Kiarashoes #Erniedrigung #Pantolette #Onlin‚Ä¶&quot; ## [4] &quot;RT @irisdarkphanta1: #erziehung ist sehr vielf√§ltig‚Ä¶. Hier eine unserer Variationen ‚Ä¶.. @Tom_PHoToToM &quot; ## [5] &quot;Kriech n√§he#Nylonlove #Genuss #Nylon #Anbeten #Dienen #Mistress #Fetisch #Fu√ü #Kiarashoes #Erniedrigung #Pantolette #Onlineerziehung #Fu√üfetisch #nylonfetish #Fu√üverehrung #highheels #Fu√ü #Feinstrumpfhose #Anbetung #Fetisch #Fu√ü #Fetischmahlzeit #Heels #session #Erziehung &quot; ## [6] &quot;Bertelsmann-Studie zu Kitas l√∂st kontroverse Reaktionen aus #Bildung #Sachsen #Erziehung #Familie #Dresden &quot; Code head (lyrik_tweets$stripped_text) ## [1] &quot;RT @o_franco_aleman: O komm, Komm zu mir, Ich bin ja so s√º√ü nach dir. Ich deine Lebendige, Deine weilende Zier, Vergehe nach dir. Peter Hi‚Ä¶&quot; ## [2] &quot;#FreieTexte #FreieTexte #Lyrik #Ichwolltesw√§reallesnursch√∂n #Gedicht Ich wollt, es w√§re alles nur sch√∂n!: Ich wollt`, es w√§re alles nur sch√∂n ‚Äì jeder w√ºrde den anderen allein als Gl√ºcksfall seh`n! Ein Miteinander w√§re weit und breit und nirgendwo‚Ä¶ &quot; ## [3] &quot;RT @o_franco_aleman: O komm, Komm zu mir, Ich bin ja so s√º√ü nach dir. Ich deine Lebendige, Deine weilende Zier, Vergehe nach dir. Peter Hi‚Ä¶&quot; ## [4] &quot;RT @o_franco_aleman: O komm, Komm zu mir, Ich bin ja so s√º√ü nach dir. Ich deine Lebendige, Deine weilende Zier, Vergehe nach dir. Peter Hi‚Ä¶&quot; ## [5] &quot;RT @o_franco_aleman: Im Namen der #Liebe verschenken wir das #Herz. Ich verblute. Peter Turrini #lyrik #poesie #fotografie &quot; ## [6] &quot;RT @o_franco_aleman: O komm, Komm zu mir, Ich bin ja so s√º√ü nach dir. Ich deine Lebendige, Deine weilende Zier, Vergehe nach dir. Peter Hi‚Ä¶&quot; 8.4 Data Pre-Processing: Transformieren F√ºr die Darstellung der Daten in einer H√§ufigkeitstabelle respektive in einer Wordcloud, m√ºssen wir die Texte mithilfe den Paketen dplyr und tidytext in einzelne W√∂rter zerlegen. Code ##Tweets in einzelne Worte zerlegen erziehung_tweets_clean &lt;- erziehung_tweets %&gt;% select(stripped_text) %&gt;% unnest_tokens(word, stripped_text) lyrik_tweets_clean &lt;- lyrik_tweets %&gt;% select(stripped_text) %&gt;% unnest_tokens(word, stripped_text) 8.5 Data Visualization: H√§ufigkeitstabelle Nun werfen wir einen ersten Blick auf den Stand der Daten √ºber eine H√§ufigkeitstabelle. Mithilfe des Pakets ggplot2. visualisieren wir die Twitter Daten: erziehung_tweets_clean Code erziehung_tweets_clean %&gt;% count(word, sort = TRUE) %&gt;% top_n(15) %&gt;% mutate(word = reorder(word, n)) %&gt;% ggplot(aes(x = word, y = n)) + geom_col(fill=&#39;steelblue4&#39;) + xlab(NULL) + coord_flip() + labs(x = &quot;Anzahl&quot;, y = &quot;W√∂rter&quot;, title = &quot;Count of unique words No. 1&quot;, subtitle=&quot;Tweets using #Erziehung&quot;, caption = paste(&quot;Source: Data collected from TwitterAPI via rtweet-package &quot;,Sys.Date())) Offensichtlich enth√§lt die Tabelle noch W√∂rter, die wenig aussagekr√§ftig sind. Aus diesem Grund erscheint es sinnvoll die Daten um deutsche ‚ÄòStopwords‚Äô zu bereinigen. Hierf√ºr verwenden wir das Paket stopwords. Falls das Paket noch nicht in der RStudio beziehungsweise in der RStudio Cloud Bibliothek vorhanden ist, installiere das Paket und lies es ein. Code #Bereinigung um deutsche Stop-Words stopwords_de &lt;- tibble(word = stopwords::stopwords(language = &quot;de&quot;,source=&quot;stopwords-iso&quot;)) erziehung_tweets_clean &lt;- erziehung_tweets_clean %&gt;% anti_join(stopwords_de, by=&quot;word&quot;) lyrik_tweets_clean &lt;- lyrik_tweets_clean %&gt;% anti_join(stopwords_de, by=&quot;word&quot;) Nach diesem Vorgang werfen wir erneut einen Blick auf die H√§ufigkeitstabelle. Code ##Erneute Ausgabe der h√§ufigsten W√∂rter erziehung_tweets_clean %&gt;% count(word, sort = TRUE) %&gt;% top_n(15) %&gt;% mutate(word = reorder(word, n)) %&gt;% ggplot(aes(x = word, y = n)) + geom_col(fill=&#39;steelblue4&#39;) + xlab(NULL) + coord_flip() + labs(x = &quot;Anzahl&quot;, y = &quot;W√∂rter&quot;, title = &quot;Count of unique words No. 2&quot;, subtitle=&quot;Tweets using #Erziehung&quot;, caption = paste(&quot;Source: Data collected from TwitterAPI via rtweet-package &quot;,Sys.Date())) Wir k√∂nnen erkennen, dass die Daten mit der Entfernung der Stopw√∂rter aussagekr√§ftiger werden in Bezug auf meist verwendeten W√∂rter. Es ist auch m√∂glich eigene Stopw√∂rter zu entfernen, die in der H√§ufigkeitstabelle auftachen; wie beispielsweise RT, rt f√ºr ReTweet und das Wort Erziehung beziehungsweise erziehung. 8.6 Eigene Stopw√∂rter erstellen Code ownStopwords=c(&quot;RT&quot;,&quot;Erziehung&quot;, &quot;erziehung&quot;,&quot;rt&quot;) ownStopwords&lt;-data.frame(ownStopwords) ownStopwords&lt;-rename (ownStopwords, word=&quot;ownStopwords&quot;) erziehung_tweets_clean &lt;- erziehung_tweets_clean %&gt;% anti_join(ownStopwords, by=&quot;word&quot;) Nun lassen wir uns die H√§ufigkeitstabelle erneut ausgeben. In diesem Fall wird auf den obigen Code verwiesen. Der Output sollte wie folgt aussehen (die einzelnen W√∂rter k√∂nnen sich bei dir unterscheiden): 8.7 Data Visualization: Word-Cloud Eine andere Alternative zur Darstellung von H√§ufigkeitsanalysen ist die Visualisierung der Daten in einer Word-Cloud. Dazu existiert eigens ein Paket wordcloud, welche installiert und eingelesen werden muss. Wie neue Pakete hinzugef√ºgt und eingelesen werden, wurden im vorherigen Kapitel 6.2.1 erl√§utert. Genau wie in der Erstellung der H√§ufigkeitstabelle ist es erforderlich die W√∂rter zu z√§hlen. Der Unterschied ist hierbei, dass der Prozess der Ausz√§hlung im Vorfeld durchgef√ºhrt werden muss. √úber den count-Funktion werden die W√∂rter gez√§hlt und in dem Objekt erziehung_tweets_count abgespeichert. Code erziehung_tweets_count &lt;- erziehung_tweets_clean %&gt;% count(word, sort = TRUE) Welche Daten das Objekt enth√§lt, erhalten wir √ºber die head-Funktion: Ein tibble-Objekt mit zwei Spalten W√∂rter und deren H√§ufigkeit. Code head(erziehung_tweets_count) ## # A tibble: 6 √ó 2 ## word n ## &lt;chr&gt; &lt;int&gt; ## 1 findom 41 ## 2 lady__jessica 38 ## 3 00 28 ## 4 oktober 28 ## 5 termin 28 ## 6 dienen 27 Nun zur Visualisierung der Wordcloud. Es wird ein Plot √ºber die Funktion wordclouderzeugt mit den Daten, die wir im vorherigen Schritt vorbereitet haben. Das Argument words wird der Spalte word aus dem Objekt erziehung_tweets_count und die freq wird aus der Spalte der H√§ufigkeit des Objektes gespeist. Code wordcloud(words = erziehung_tweets_count$word, freq = erziehung_tweets_count$n, max.words = 50, scale = c(2,.5), colors=brewer.pal(6, &quot;Dark2&quot;)) 8.7.1 Aufgabe Die Visualisierungen sind nun auf der Datenbasis des Hashtags #Erziehung realisiert worden. F√ºhre den aufgef√ºhrten Prozess mit einem eigenen Hashtag oder mit dem Hashtag #Lyrik durch. 8.8 Quelle Zur Dokumentation des Pakets: stopwords Zur Dokumentation des Pakets: wordcloud 8.9 Feedback "],["dritte-lerneinheit---sentimentanalyse-teil-1.html", "Chapter 9 Dritte Lerneinheit - Sentimentanalyse: Teil 1 9.1 Aufgabe 9.2 Knowledge-Check 9.3 Feedback", " Chapter 9 Dritte Lerneinheit - Sentimentanalyse: Teil 1 Zur Anwendung der Sentimentanalyse ist die inhaltliche Auseinandersetzung mit dieser Art von Analyse essentiell. In diesem Sinne widmet sich das folgende Kapitel mit den inhaltlichen Elementen der Sentimentanalyse. 9.1 Aufgabe Arbeiten Sie den Eintrag zur Sentimentanalyse auf der Website fortext.net durch. F√ºhre schriftlich aus, welche Ziele mit einer Sentimentanalyse verfolgt werden und was den Gegenstand einer Sentimentanalyse ausmacht. 9.2 Knowledge-Check Was bedeutet Sentimentanaylse? Wieso eignen sich insbesondere Literarische Texte f√ºr solche Analysen? Nach welchen Methoden wird die Sentimentanalyse durchgef√ºhrt? Was sind die Pros und Contras f√ºr eine lexikonbasierte Sentimentanalyse? Vor welcher technischen Herausforderung steht die Sentimentanalyse aktuell? 9.3 Feedback "],["dritte-lerneinheit---sentimentanalyse-teil-2.html", "Chapter 10 Dritte Lerneinheit - Sentimentanalyse: Teil 2 10.1 Aufgabe 10.2 Vorbereitung 10.3 Gro√ü- und Kleinschreibung 10.4 Ergebnis des Data Pre-Processing 10.5 Lexikon/W√∂rterbuch 10.6 Erg√§nzung der positiven und negativen Sentiments 10.7 Sentimentanalyse 10.8 Visualisierung Sentimentanalyse 10.9 Sentiment-Score 10.10 Word-Cloud 10.11 Feedback", " Chapter 10 Dritte Lerneinheit - Sentimentanalyse: Teil 2 Nach der inhaltlichen Auseinandersetzung mit dem Thema befassen wir uns mit der Realisierung einer Sentimentanalyse anhand unserer Twitter-Daten. 10.1 Aufgabe Versuche die Schritte der beispielhaften Anwendung einer Sentimentanalyse im folgenden Beitrag nachzuvollziehen: towardsdatascience.com 10.2 Vorbereitung Zun√§chst lesen wir alle Pakete ein, die uns bereits bekannt sind und die wir f√ºr die Analyse brauchen. Dies sind rtweet,dplyr,tidytext,ggplot2,wordcloud,gridExtra und stopwords. Die Pakete sind insofern wichtig, da wir ebenfalls die Schritte des Data Pre-Processing wie im vorherigen Kapitel durchf√ºhren m√ºssen. Ferner greifen wir erneut auf die Twitter-API, sodass eine Authentizifierung √ºber das entsprechende Paket notwendig ist. Die Analyse wird beispielhaft mit dem Hashtag #Lyrik durchgef√ºhrt. In diesem Zusammenhang wird vorausgesetzt, dass: die Suche nach dem #Lyrik bereits vollzogen ist, die Daten bereinigt wurden und die Stopw√∂rter entfernt wurden 10.3 Gro√ü- und Kleinschreibung F√ºr die Analyse werden die Tweets - wie bekannt - in einzelne W√∂rter zerlegt. Jedoch kommt f√ºr diese Analyse ein zus√§tzlicher Schritt hinzu. Die einzelnen W√∂rter sollen nicht ins kleingeschriebene konvertiert werden. Das Vorgehen ist insofern notwendig, da das verwendete Lexikon f√ºr die Sentimentanalyse kleingeschriebene und gro√ügeschriebenen W√∂rter kennt. Der Code daf√ºr lautet wie folgt: Code lyrik_tweets_clean &lt;- lyrik_tweets %&gt;% select(stripped_text) %&gt;% unnest_tokens(word, stripped_text, to_lower=FALSE) Die default-Einstellung in dem Vorgehen ist die W√∂rter ins kleingeschriebene zu konvertieren. 10.4 Ergebnis des Data Pre-Processing Das Ergebnis sollte - in √§hnlicher Weise - in einer H√§ufigkeitstabelle folgenderma√üen aussehen: 10.5 Lexikon/W√∂rterbuch Das Lexikon, welches f√ºr die Sentimentanalyse verwendet wird, stammt von der Universit√§t Leipzig: Leipzig Corpora Collection aus dem Projekt Deutscher Wortschatz. Ferner bedienen wir uns f√ºr die Importierung des W√∂rterbuches an einen bereits fertigen Code von dem Github User Polmine, der das Paket data.tableben√∂tigt. Das W√∂rterbuch wird anschlie√üend in dem Objekt all_sentiments abgespeichert. Code # Import SentiWS dictionary for sentiment analysis into R as data.table # Source: https://gist.github.com/PolMine/70eeb095328070c18bd00ee087272adf library(data.table) # Definition einer Funktion namens &quot;get_sentiws()&quot; get_sentiws &lt;- function(){ sentiws_tmp_dir &lt;- file.path(tempdir(), &quot;sentiws&quot;) if (!file.exists(sentiws_tmp_dir)) dir.create(sentiws_tmp_dir) sentiws_zipfile &lt;- file.path(sentiws_tmp_dir, &quot;SentiWS_v2.0c.zip&quot;) sentiws_url &lt;- &quot;http://pcai056.informatik.uni-leipzig.de/downloads/etc/SentiWS/SentiWS_v2.0.zip&quot; download.file(url = sentiws_url, destfile = sentiws_zipfile) unzip(zipfile = sentiws_zipfile, exdir = sentiws_tmp_dir) .unfold &lt;- function(.SD){ pos &lt;- gsub(&quot;^([A-Z]+)\\\\s+.*$&quot;, &quot;\\\\1&quot;, .SD[[&quot;data&quot;]][1]) weight &lt;- as.numeric(gsub(&quot;^[A-Z]+\\\\s+(-?\\\\d\\\\.\\\\d+).*$&quot;, &quot;\\\\1&quot;, .SD[[&quot;data&quot;]][1])) words &lt;- gsub(&quot;^[A-Z]+\\\\s+-?\\\\d\\\\.\\\\d+\\\\s*(.*?)\\\\s*$&quot;, &quot;\\\\1&quot;, .SD[[&quot;data&quot;]][1]) words &lt;- if (!grepl(&quot;^\\\\s*$&quot;, words)) strsplit(x = words, split = &quot;,&quot;)[[1]] else NULL list( word = c(.SD[[&quot;word&quot;]][1], words), base = c(TRUE, rep(FALSE, times = length(words))), lemma = .SD[[&quot;word&quot;]][1], pos = pos, weight = weight ) } dts &lt;- lapply( c(positive = &quot;SentiWS_v2.0_Positive.txt&quot;, negative = &quot;SentiWS_v2.0_Negative.txt&quot;), function(filename){ dt &lt;- fread(file.path(sentiws_tmp_dir, filename), sep = &quot;|&quot;) colnames(dt) &lt;- c(&quot;word&quot;, &quot;data&quot;) dt[, &quot;id&quot; := 1L:nrow(dt)] dt[, .unfold(.SD), by = c(&quot;id&quot;)] } ) rbindlist(dts) } #Abspeicherung des W√∂rterbuches all_sentiments &lt;- get_sentiws() 10.6 Erg√§nzung der positiven und negativen Sentiments Das bereitgestellte Lexikon der Universit√§t Leipzig besitzt eine ausdifferenzierte numerische Gewichtung √ºber die Bewertung der W√∂rter als positiv oder als negativ. F√ºr unsere Zwecke vereinfachen wir die Gewichtung und differenzieren nur zwischen positiven und negativen Sentiments. Das hei√üt wir transformieren ein metrisches Merkmal in ein kategoriales Merkmal. Code all_sentiments_lexikon_neg &lt;- all_sentiments %&gt;% filter(weight &lt;= 0) %&gt;% mutate(sentiment = &quot;negativ&quot;) all_sentiments_lexikon_pos &lt;- all_sentiments %&gt;% filter(weight &gt; 0) %&gt;% mutate(sentiment = &quot;positiv&quot;) all_sentiments_lexikon &lt;- merge(all_sentiments_lexikon_neg, all_sentiments_lexikon_pos, all=T) Anschlie√üend wollen wir uns das gesamte Lexikon anschauen: Code # zeige gesamtes Lexikon head(all_sentiments_lexikon) ## id word base lemma pos weight sentiment ## 1: 1 Abbruch TRUE Abbruch NN -0.0048 negativ ## 2: 1 Abbruche FALSE Abbruch NN -0.0048 negativ ## 3: 1 Abbruches FALSE Abbruch NN -0.0048 negativ ## 4: 1 Abbruchs FALSE Abbruch NN -0.0048 negativ ## 5: 1 Abbr√ºche FALSE Abbruch NN -0.0048 negativ ## 6: 1 Abbr√ºchen FALSE Abbruch NN -0.0048 negativ Zur √úberpr√ºfung der Transformation werfen wir einen Blick auf die positiven und negativen Sentiments: Code # zeige positive Lexikon-Eintr√§ge all_sentiments_lexikon %&gt;% filter (sentiment==&quot;positiv&quot;) ## id word base lemma pos weight sentiment ## 1: 1 Abschluss FALSE Abschlu√ü NN 0.004 positiv ## 2: 1 Abschlusse FALSE Abschlu√ü NN 0.004 positiv ## 3: 1 Abschlusses FALSE Abschlu√ü NN 0.004 positiv ## 4: 1 Abschlu√ü TRUE Abschlu√ü NN 0.004 positiv ## 5: 1 Abschl√ºsse FALSE Abschlu√ü NN 0.004 positiv ## --- ## 16561: 1643 √ºppigste FALSE √ºppig ADJX 0.201 positiv ## 16562: 1643 √ºppigstem FALSE √ºppig ADJX 0.201 positiv ## 16563: 1643 √ºppigsten FALSE √ºppig ADJX 0.201 positiv ## 16564: 1643 √ºppigster FALSE √ºppig ADJX 0.201 positiv ## 16565: 1643 √ºppigstes FALSE √ºppig ADJX 0.201 positiv Code # zeige negative Lexikon-Eintr√§ge all_sentiments_lexikon %&gt;% filter (sentiment==&quot;negativ&quot;) ## id word base lemma pos weight sentiment ## 1: 1 Abbruch TRUE Abbruch NN -0.0048 negativ ## 2: 1 Abbruche FALSE Abbruch NN -0.0048 negativ ## 3: 1 Abbruches FALSE Abbruch NN -0.0048 negativ ## 4: 1 Abbruchs FALSE Abbruch NN -0.0048 negativ ## 5: 1 Abbr√ºche FALSE Abbruch NN -0.0048 negativ ## --- ## 18026: 1826 √ºberw√§ltigt FALSE √ºberw√§ltigen VVINF -0.0048 negativ ## 18027: 1826 √ºberw√§ltigte FALSE √ºberw√§ltigen VVINF -0.0048 negativ ## 18028: 1826 √ºberw√§ltigten FALSE √ºberw√§ltigen VVINF -0.0048 negativ ## 18029: 1826 √ºberw√§ltigtest FALSE √ºberw√§ltigen VVINF -0.0048 negativ ## 18030: 1826 √ºberw√§ltigtet FALSE √ºberw√§ltigen VVINF -0.0048 negativ 10.7 Sentimentanalyse Nun k√∂nnen wir mit der eigentlichen Sentimentanalyse fortfahren. Daf√ºr gleichen wir die lyrik-Tweets mit dem Lexikon ab und z√§hlen die √úbereinstimmungen. Anschlie√üend geben wir das Ergebnis in dem neuen Objekt sentiment_analysis_lyrik mit dem head()-Befehl aus. Code sentiment_analyse_lyrik&lt;- lyrik_tweets_clean %&gt;% inner_join(all_sentiments_lexikon) %&gt;% count(word, sentiment, sort = T) %&gt;% ungroup() head(sentiment_analyse_lyrik) ## # A tibble: 6 √ó 3 ## word sentiment n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 lernen positiv 108 ## 2 ruhig positiv 19 ## 3 mutiger positiv 16 ## 4 wunderbaren positiv 8 ## 5 Liebe positiv 6 ## 6 hebt positiv 4 10.8 Visualisierung Sentimentanalyse Mithilfe einer H√§ufigkeitstabelle erhalten wir uns nun einen tieferen Einblick in die Daten. An dieser Stelle soll erneut darauf hingewiesen, dass das Merkmal sentiment als eine kategoriale Variable zu behandeln ist Code sentiment_analyse_lyrik %&gt;% group_by(sentiment) %&gt;% top_n(15) %&gt;% ungroup() %&gt;% mutate(word = reorder(word,n)) %&gt;% ggplot(aes(word,n, fill=sentiment)) + geom_col(show.legend = F) + #facet_wrap: Unterscheidung zwischen den beiden Auspr√§gungen: positiv und negativ. facet_wrap(~sentiment, scales=&quot;free_y&quot;) + labs(title=&quot;Tweets #Lyrik&quot;, y= &quot;Anteil am Sentiment&quot;, x= NULL)+ coord_flip() + theme_bw() 10.9 Sentiment-Score Ferner erm√∂glicht die Gewichtung des Lexikon die Berechnung eines Sentiment-Scores f√ºr den Tweets-Datensatz. Der Sentiment-Score bewertet die Stimmung eines Transkripts beziehungsweise der Tweets in Bezug auf einem Spektrum von positiv (Wert 1) bis negativ (-1) bewerten. F√ºr die Berechnung des Sentiment-Scores werden die Ergebnisse in dem Objekt sentiment_score_lyrik abgespeichert. Code sentiment_score_lyrik&lt;- lyrik_tweets_clean %&gt;% inner_join(all_sentiments_lexikon) %&gt;% count(word, sentiment, weight, sort = T) %&gt;% ungroup() #Berechnung des Scores: Gewichtung * H√§ufigkeit sentiment_score_lyrik &lt;- sentiment_score_lyrik %&gt;% mutate(score = weight*n) Mithilfe des Histogramms betrachten wir in welche Richtung die Tweets gelagert sind. Daf√ºr lassen wir uns zwei unterschiedliche Histogramme anzeigen. F√ºr die Einteilung des Histogramms existieren bestimmte Faustregeln, die an dieser Stelle nicht weiter erl√§utert werden. Die Berechnungsgrundlage ist die Wurzel aus der Anzahl an allen W√∂rtern. Das erste Histogramm teilen wir ein in 9 Klassen ein: Code ggplot(sentiment_score_lyrik, aes(x=weight)) + geom_histogram(bins = 9, alpha = 0.6) + theme_bw() + labs(title=&quot;Histogram Twitter - Sentiment Score&quot;, y=&quot;Anzahl&quot;, x=&quot;Sentiment Score&quot;) Das zweite Histogramm wird in 18 Klassen eingeteilt: Code ggplot(sentiment_score_lyrik, aes(x=weight)) + geom_histogram(bins = 18, alpha = 0.6) + theme_bw() + labs(title=&quot;Histogram Twitter - Sentiment Score&quot;, y=&quot;Anzahl&quot;, x=&quot;Sentiment Score&quot;) In beiden Graphen ist zu erkennen, dass die Mehrheit der W√∂rter in den Tweets eher neutral sind. Erg√§nzend l√§sst sich eine st√§rkere Gewichtung eines positiven Trends erkennen als eines negativen Trends. Letzteres ist insbesondere im zweiten Histogramm wahrzunehmen. 10.10 Word-Cloud Selbstverst√§ndlich ist es m√∂glich die H√§ufigkeitstabelle in einer Word-Cloud darzustellen. Erstelle jeweils eine Word-Cloud f√ºr die beiden Sentiments (positiv und negativ) 10.11 Feedback "],["abschluss-aufgabe.html", "Chapter 11 Abschluss Aufgabe 11.1 Inhalt 11.2 Einf√ºhrung in RMarkdown 11.3 Feedback", " Chapter 11 Abschluss Aufgabe Zur Dokumentation der Ergebnisse in RStudio eigent sich das Format RMarkdown. RMarkdown basiert auf einer Markdown-Syntax mit dem Ziel eine lesbare Ausgansform vor der Konvertierung in anderes (bekannteres) Format wie einer PDF-Datei oder einer Word-Datei darzustellen. 11.1 Inhalt Analyse eines Hashtags und die Dokumentierung der Ergebnisse oder deines Analyse-Prozesses in einem Rmarkdown-Dokument In dieser Aufgabe werden viele Elemente vorausgesetzt, die in den vorherigen Kapitel dargelegt werden. Dies ist Absicht. Besonders effektiv kann gelerntes durch Anwendung gefestigt werden. An dieser Stelle m√∂chten wir dich ermutigen bei Fragen oder Unsicherheit die entsprechenden Kapiteln anzusteuern, das Feedback-Feld zu nutzen oder deine Kommilitonen_innnen um Rat zu fragen. 11.2 Einf√ºhrung in RMarkdown Zur Erstellung eines RMarkdown-Dokuments schau dir folgende Ressourcen an: Video-Tutorial von Sebastian Sauer zur Einf√ºhrung in RMarkdown Schritt f√ºr Schritt Anleitung Des Weiteren k√∂nnen wir auf Anfrage ein exemplarisches Dokument bereitstellen. 11.3 Feedback "]]
